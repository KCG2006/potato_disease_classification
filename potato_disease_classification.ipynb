{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48e2496-3dda-4630-a9e3-ecc81a7beef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e39adf7-f8da-4b62-8d0c-c2545d4a4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can use data augmentation in this line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e8c3e49-b848-4e61-8602-e90b6e1d21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset, it combine all three folders into one\n",
    "dataset = datasets.ImageFolder(root=\"F:/dataset/potato_disease\", \n",
    "                               transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc05d2a-ed3d-4fbc-856e-fea50b5c3d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 152, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we must split into 3 separate classes, \n",
    "#because if we just randomly split into train/dev/test, they might be very skewed\n",
    "early_blight = []\n",
    "healthy = []\n",
    "late_blight = []\n",
    "for ex in range(len(dataset)):\n",
    "    if dataset[ex][1] == 0:\n",
    "        early_blight.append(dataset[ex])\n",
    "    elif dataset[ex][1] ==1: \n",
    "        healthy.append(dataset[ex])\n",
    "    else:\n",
    "        late_blight.append(dataset[ex])\n",
    "len(early_blight), len(healthy), len(late_blight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ca919c-2a0f-4c7d-bf16-4248ac65135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom datasets that are the same as above (list) but with extra Pytorch features\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        #change label to tensor too\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9872ee4f-d5ff-4979-85ff-f1fd936c4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change healthy, early_blight, late_blight to dataset, then split into train and test set, and then concat all three of them\n",
    "## -> finally turn them into train_dataloader, test_dataloader\n",
    "healthy_data = CustomDataset(healthy)\n",
    "train_size = int(0.8*len(healthy_data))\n",
    "test_size = len(healthy_data) - train_size\n",
    "healthy_train, healthy_test = random_split(healthy_data, [train_size, test_size])\n",
    "\n",
    "early_data = CustomDataset(early_blight)\n",
    "train_size = int(0.8*len(early_data))\n",
    "test_size = len(early_data) - train_size\n",
    "early_train, early_test = random_split(early_data, [train_size, test_size])\n",
    "\n",
    "late_data = CustomDataset(late_blight)\n",
    "train_size = int(0.8*len(late_data))\n",
    "test_size = len(late_data) - train_size\n",
    "late_train, late_test = random_split(late_data, [train_size, test_size])\n",
    "\n",
    "#concat them using ConcatDataset\n",
    "train_data = torch.utils.data.ConcatDataset([healthy_train, early_train, late_train])\n",
    "test_data = torch.utils.data.ConcatDataset([healthy_test, early_test, late_test])\n",
    "\n",
    "#turn them into DataLoader\n",
    "train_dataloader = DataLoader(train_data, batch_size = 32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = 32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed154633-daf9-49ec-af26-fab6239965f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dataloader:\n",
    "    print(images.shape)   # e.g. [32, 3, 224, 224]\n",
    "    print(labels.shape)   # e.g. [32]\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c60bf0f-8b01-49bd-8335-f01c4fd0dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(10, 10, kernel_size = 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(63*63*10, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 63*63*10)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca8c4678-b73b-4c24-940f-08f793869d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup device agnostic code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a65c2459-99de-4af5-b809-56586cfff1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance\n",
    "model = CNN().to(device)\n",
    "\n",
    "#setup metrics, loss, optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(),\n",
    "                             lr = 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b66cd6-7134-4c4b-9a55-03ebce7ead04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
